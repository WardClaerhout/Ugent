
   "source": [
    "# Domain of the parameter p of a Bernoulli rv: p âˆˆ [0, 1]\n",
    "p = np.linspace(0, 1, 1000)\n",
    "\n",
    "def xln2x(x):\n",
    "    \"\"\" Computes x * log_2(x) in a safe way.\"\"\"\n",
    "    # If x is not a numpy array, it becomes one\n",
    "    \n",
    "    if not isinstance(x, np.ndarray):\n",
    "        y = 0\n",
    "\n",
    "    if x == 0:\n",
    "        y = 0\n",
    "    else:  \n",
    "        y = x* math.log2(x)\n",
    "    return y\n",
    "\n",
    "q = xln2x(0.5)\n",
    "print(q)\n",
    "entropy = np.zeros(len(p))\n",
    "\n",
    "for i in range(len(entropy)):\n",
    "    entropy[i] = -xln2x(p[i])-xln2x(1-p[i])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Entropy of a Bernoulli random variable\")\n",
    "plt.plot(p, entropy)\n",
    "plt.xlabel(\"Probability of heads\")\n",
    "plt.gca().get_xaxis().set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "plt.ylabel(\"Entropy [bits]\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-05T11:07:36.677016Z",
     "start_time": "2021-02-05T11:07:36.628770Z"
    }
   },
   "source": [
    "## Entropy of a sequence\n",
    "\n",
    "Let's now make the distinction between the empirical entropy -- the average information in a sequence -- with the information content -- how much information there is in total in a sequence. For instance, a fair coin has an entropy of 1 bit, but when tossed 4 times has an information content of 4 bits (a.k.a a nibble).\n",
    "\n",
    "Now implement a function that calculates the entropy of a binary sequence yourself. First, calcultate the parameter p, then plug it in the formula of the entropy (bernoulli)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T09:38:08.945369Z",
     "start_time": "2021-02-09T09:38:08.927559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.5\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.8888888888888888\n",
      "0.5032583347756459\n"
     ]
    }
   ],
   "source": [
    "def binary_entropy(seq):\n",
    "    \"\"\" Returns the empirical entropy of a sequence.\n",
    "    Input values should contain only 0s and 1s.\"\"\"\n",
    "    # If seq is not a numpy array, it becomes one\n",
    "    if not isinstance(seq, np.ndarray):\n",
    "        seq = np.array(seq)\n",
    "    if len(seq) == 0:\n",
    "        entropy = 0\n",
    "    else:\n",
    "        p = np.mean(seq)\n",
    "        entropy = -xln2x(p)-xln2x(1-p)\n",
    "    return entropy\n",
    "\n",
    "assert binary_entropy([0]) == 0, \"Failed test 1\"\n",
    "assert binary_entropy([0, 1]) == 1, \"Failed test 2\"\n",
    "assert binary_entropy([0]*10 + [1]*10) == 1, \"Failed test 3\"\n",
    "assert np.abs(binary_entropy([0] + [1]*8) - 0.50326) < 1e-5, \"Failed test 4\"\n",
    "assert binary_entropy([]) == 0, \"Failed test 5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the sequence has more than two outcomes\n",
    "\n",
    "Unlike the coin toss, there can be situations where there are more than two outcomes. Rolling a dice is a situation where there are 6 outcomes (assuming the dice has 6 faces). When a fair dice is rolled, one can get either 1 or 2 or 3 or 4 or 5 or 6. Each face has an equal probability to appear. We can still calculate the entropy using the definition introduced at the very beginning of this notebook.\n",
    "\n",
    "Now implement a funtion that calculates the entropy of a random sequence. Make sure you use `xln2x(p)` to calculate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(sequence):\n",
    "    # Assume that sequence is a pandas data frame\n",
    "    entropy = 0.0\n",
    "    outcomes = len(sequence)\n",
    "    p = 1/len(sequence)\n",
    "    \n",
    "    entropy = outcomes * (-xln2x(p))\n",
    "    return entropy\n",
    "\n",
    "sequence = pd.DataFrame(data=[1/6 for i in range(6)])\n",
    "assert calculate_entropy(sequence) == 2.584962500721156, \"Failed test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the animal in 20 questions\n",
    "\n",
    "As a kid, you might have travelled by car over long distances and been bored for hours on end and played this game: find the animal/object in so many questions. Perhaps you just were lucky and played the Sims 2 on a portable PlayStation 2. Whatever.\n",
    "\n",
    "This exercise consists of automating the 20 questions game such that it asks 20 questions (or more or less) to find an animal the player has chosen. When you have kids on your own someday (or already), you can entertain your kids for 12+ hours when you travel.\n",
    "\n",
    "You are given a dataset, the columns correspond to features, the rows to names of animals. A given animal has a set of binary features. For instance, a bear has hair, lactate, is a mammal and predator, has teeth, breathes, and so on.\n",
    "\n",
    "You will have to implement an algorithm that creates a binary decision tree and use this tree to create a questionaire (this step is already done for you below) and find an animal in as few guesses as possible.\n",
    "The algorithm to use is ID3, you can refer to the [lecture material](https://user.it.uu.se/~justin/Hugo/courses/machinelearning/lecture8/) to find the algorithm. The measure to use is the entropy and the information gain to choose the top most nodes in the decision tree. The feature with the higher information gain will be closer to the root node. You will have to implement the function `information_gain()` to help with `generate_tree()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T09:38:22.356958Z",
     "start_time": "2021-02-09T09:38:22.232210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is it warm blooded?</th>\n",
       "      <th>can it fly?</th>\n",
       "      <th>is it a vertebrate?</th>\n",
       "      <th>is it endangered?</th>\n",
       "      <th>does it live in groups?</th>\n",
       "      <th>does it have hair?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bee</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpl</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duck</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      is it warm blooded?  can it fly?  is it a vertebrate?  \\\n",
       "ant                     0            0                    0   \n",
       "bee                     0            1                    0   \n",
       "cat                     1            0                    1   \n",
       "cpl                     0            0                    0   \n",
       "duck                    1            1                    1   \n",
       "\n",
       "      is it endangered?  does it live in groups?  does it have hair?  \n",
       "ant                   0                        1                   0  \n",
       "bee                   0                        1                   1  \n",
       "cat                   0                        0                   1  \n",
       "cpl                   0                        0                   1  \n",
       "duck                  0                        1                   0  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download and load the dataset into pandas\n",
    "dataset_url = \"https://raw.githubusercontent.com/earthtojake/20q/master/data/small.csv\"\n",
    "# There is a bigger dataset at\n",
    "# dataset_url = \"https://raw.githubusercontent.com/earthtojake/20q/master/data/big.csv\"\n",
    "df = pd.read_csv(dataset_url, index_col=0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(sample, feature):\n",
    "    # Assume that sample is a pandas data frame\n",
    "    # Assume that feature is some column appearing in sample.\n",
    "    col = sample.iloc[:,feature]\n",
    "    p = np.mean(col)\n",
    "    p_cond = -xln2x(p)-xln2x(1-p)\n",
    "    G = calculate_entropy(col) - p*p_cond\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[3.0849625  3.27886389 2.97276528 3.38214297 3.01337239 3.17668385]\n"
     ]
    }
   ],
   "source": [
    "rows, columns = np.shape(df)\n",
    "print(columns)\n",
    "entropies = np.zeros(columns)\n",
    "print(entropies)\n",
    "for i in range(columns):\n",
    "    entropies[i] = information_gain(df, i)\n",
    "\n",
    "print(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T09:38:47.846885Z",
     "start_time": "2021-02-09T09:38:47.774720Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropies = [3.0849625  3.27886389 2.97276528 3.38214297 3.01337239 3.17668385]\n",
      " indices = []\n",
      "Shape of data: (12, 6)\n",
      "No column left: False\n",
      "One animal left: False\n",
      "information gain = [3.0849625  3.27886389 2.97276528 3.38214297 3.01337239 3.17668385]\n",
      "selected column index = 3\n",
      " selected_column = is it endangered?\n",
      " selected_column_index = 3\n",
      "entropies = [1.5849625  1.27886389 1.5849625  0.97276528 1.27886389]\n",
      " indices = []\n",
      "Shape of data: (3, 5)\n",
      "No column left: False\n",
      "One animal left: False\n",
      "information gain = [1.5849625  1.27886389 1.5849625  0.97276528 1.27886389]\n",
      "selected column index = 0\n",
      " selected_column = is it warm blooded?\n",
      " selected_column_index = 0\n",
      "entropies = [1.27886389 1.5849625  0.97276528 1.27886389]\n",
      " indices = []\n",
      "Shape of data: (3, 4)\n",
      "No column left: False\n",
      "One animal left: False\n",
      "information gain = [1.27886389 1.5849625  0.97276528 1.27886389]\n",
      "selected column index = 1\n",
      " selected_column = is it a vertebrate?\n",
      " selected_column_index = 1\n",
      "entropies = [1.27886389 0.97276528 1.27886389]\n",
      " indices = []\n",
      "Shape of data: (3, 3)\n",
      "No column left: False\n",
      "One animal left: False\n",
      "information gain = [1.27886389 0.97276528 1.27886389]\n",
      "selected column index = 0\n",
      " selected_column = can it fly?\n",
      " selected_column_index = 0\n",
      "entropies = [-0. -0.]\n",
      " indices = [0 1]\n",
      "Shape of data: (1, 0)\n",
      "No column left: True\n",
      "One animal left: True\n",
      "entropies = [1.  0.5]\n",
      " indices = []\n",
      "Shape of data: (2, 2)\n",
      "No column left: False\n",
      "One animal left: False\n",
      "information gain = [1.  0.5]\n",
      "selected column index = 0\n",
      " selected_column = does it live in groups?\n",
      " selected_column_index = 0\n",
      "entropies = [0.5]\n",
      " indices = []\n",
      "Shape of data: (2, 1)\n",
      "No column left: False\n",
      "One animal left: False\n",
      "information gain = [0.5]\n",
      "selected column index = 0\n",
      " selected_column = does it have hair?\n",
      " selected_column_index = 0\n",
      "entropies = []\n",
      " indices = []\n",
      "Shape of data: (1, 0)\n",
      "No column left: True\n",
      "One animal left: True\n",
      "entropies = []\n",
      " indices = []\n",
      "Shape of data: (1, 0)\n",
      "No column left: True\n",
      "One animal left: True\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[197], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m     generate_tree(data[\u001b[38;5;241m~\u001b[39mmask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# The tree is generated\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m generate_tree(df, tree)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# The tree is plotted\u001b[39;00m\n\u001b[0;32m     81\u001b[0m tree\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn[197], line 74\u001b[0m, in \u001b[0;36mgenerate_tree\u001b[1;34m(data, tree, branch, parent)\u001b[0m\n\u001b[0;32m     71\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop(data\u001b[38;5;241m.\u001b[39mcolumns[selected_column_index], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)    \n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# We generate the branches **recursively**\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# If the answer to the question was \"yes\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m generate_tree(data[mask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# If the answer to the question was \"false\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m generate_tree(data[\u001b[38;5;241m~\u001b[39mmask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n",
      "Cell \u001b[1;32mIn[197], line 74\u001b[0m, in \u001b[0;36mgenerate_tree\u001b[1;34m(data, tree, branch, parent)\u001b[0m\n\u001b[0;32m     71\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop(data\u001b[38;5;241m.\u001b[39mcolumns[selected_column_index], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)    \n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# We generate the branches **recursively**\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# If the answer to the question was \"yes\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m generate_tree(data[mask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# If the answer to the question was \"false\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m generate_tree(data[\u001b[38;5;241m~\u001b[39mmask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n",
      "Cell \u001b[1;32mIn[197], line 74\u001b[0m, in \u001b[0;36mgenerate_tree\u001b[1;34m(data, tree, branch, parent)\u001b[0m\n\u001b[0;32m     71\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop(data\u001b[38;5;241m.\u001b[39mcolumns[selected_column_index], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)    \n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# We generate the branches **recursively**\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# If the answer to the question was \"yes\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m generate_tree(data[mask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# If the answer to the question was \"false\"\u001b[39;00m\n\u001b[0;32m     76\u001b[0m generate_tree(data[\u001b[38;5;241m~\u001b[39mmask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n",
      "Cell \u001b[1;32mIn[197], line 76\u001b[0m, in \u001b[0;36mgenerate_tree\u001b[1;34m(data, tree, branch, parent)\u001b[0m\n\u001b[0;32m     74\u001b[0m generate_tree(data[mask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# If the answer to the question was \"false\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m generate_tree(data[\u001b[38;5;241m~\u001b[39mmask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n",
      "Cell \u001b[1;32mIn[197], line 76\u001b[0m, in \u001b[0;36mgenerate_tree\u001b[1;34m(data, tree, branch, parent)\u001b[0m\n\u001b[0;32m     74\u001b[0m generate_tree(data[mask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# If the answer to the question was \"false\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m generate_tree(data[\u001b[38;5;241m~\u001b[39mmask], tree, branch\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, parent\u001b[38;5;241m=\u001b[39mnode)\n",
      "Cell \u001b[1;32mIn[197], line 24\u001b[0m, in \u001b[0;36mgenerate_tree\u001b[1;34m(data, tree, branch, parent)\u001b[0m\n\u001b[0;32m     21\u001b[0m entropies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(columns)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(columns):\n\u001b[1;32m---> 24\u001b[0m     entropies[i] \u001b[38;5;241m=\u001b[39m information_gain(data, i)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentropies = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentropies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# The columns with a null entropy can be removed\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[178], line 7\u001b[0m, in \u001b[0;36minformation_gain\u001b[1;34m(sample, feature)\u001b[0m\n\u001b[0;32m      5\u001b[0m p \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(col)\n\u001b[0;32m      6\u001b[0m p_cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mxln2x(p)\u001b[38;5;241m-\u001b[39mxln2x(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mp)\n\u001b[1;32m----> 7\u001b[0m G \u001b[38;5;241m=\u001b[39m calculate_entropy(col) \u001b[38;5;241m-\u001b[39m p\u001b[38;5;241m*\u001b[39mp_cond\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "Cell \u001b[1;32mIn[79], line 5\u001b[0m, in \u001b[0;36mcalculate_entropy\u001b[1;34m(sequence)\u001b[0m\n\u001b[0;32m      3\u001b[0m entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m outcomes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sequence)\n\u001b[1;32m----> 5\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(sequence)\n\u001b[0;32m      7\u001b[0m entropy \u001b[38;5;241m=\u001b[39m outcomes \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mxln2x(p))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m entropy\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "tree = Tree()\n",
    "tree.create_node(\"Root\", \"root\")  # root node\n",
    "\n",
    "def generate_tree(data, tree, branch=\"\", parent=\"root\"):\n",
    "    \"\"\"Populates the tree with questions and candidate animals.\n",
    "    \n",
    "    Args:\n",
    "        data: The dataset to use\n",
    "        tree: The tree to populate\n",
    "        branch: '+' if the previous condition was true, '-' otherwise.\n",
    "        parent: The parent node, so that we can attach children nodes to it.\n",
    "    \n",
    "    Note: Treelib sorts the name of the nodes by alphabetical order, its important\n",
    "    to name the nodes such that the first one is the result of a positive condition,\n",
    "    the second one, the negative condition. This has been taken care of if you use\n",
    "    the code template by naming the node \"+something\" and \"-something\" (In ASCII, +\n",
    "    (42) is before - (45)).\n",
    "    \"\"\"\n",
    "    # Find the column with the highest entropy\n",
    "    rows, columns = np.shape(data)\n",
    "    entropies = np.zeros(columns)\n",
    "    \n",
    "    for i in range(columns):\n",
    "        entropies[i] = information_gain(data, i)\n",
    "\n",
    "    print(f\"entropies = {entropies}\")\n",
    "    \n",
    "    # The columns with a null entropy can be removed\n",
    "    indices = np.where(entropies == 0)[0]\n",
    "    print(f\" indices = {indices}\")\n",
    "    data = data.drop(data.columns[indices], axis=1)    # If there is only one animal and plenty of columns, we also stop\n",
    "    \n",
    "    no_column_left = True if np.shape(data)[1] == 0 else False\n",
    "    one_animal_left = True if np.shape(data)[0] == 1 else False\n",
    "    \n",
    "    print(\"Shape of data:\", data.shape)\n",
    "    print(\"No column left:\", no_column_left)\n",
    "    print(\"One animal left:\", one_animal_left)\n",
    "    print(\"parent =\",parent)\n",
    "    \n",
    "    if no_column_left or one_animal_left:\n",
    "        tree.create_node(branch+\", \".join(data.index), parent=parent)\n",
    "        return parent\n",
    "    \n",
    "    # If we are here, it means the data can be split some more.\n",
    "    # entropies might have more columns than the current data, since\n",
    "    # we removed some columns.\n",
    "    entropies = np.delete(entropies, indices)    \n",
    "    \n",
    "    # We find the column with the highest entropy\n",
    "    rows, columns = np.shape(data)\n",
    "    information = np.zeros(columns)\n",
    "\n",
    "    for i in range(columns):\n",
    "        information[i] = information_gain(data, i)\n",
    "        \n",
    "    print(f\"information gain = {information}\")\n",
    "    selected_column_index = np.argmax(information)\n",
    "    print(f\"selected column index = {selected_column_index}\")\n",
    "    selected_column = data.columns[selected_column_index]\n",
    "    \n",
    "    # We add the column to the tree under the current parent\n",
    "    node = tree.create_node(branch + selected_column, parent=parent)\n",
    "    \n",
    "    # we split the data by column and remove the said column\n",
    "    mask = data.iloc[:, selected_column_index] == 1 \n",
    "    print(f\" selected_column = {selected_column}\")\n",
    "    print(f\" selected_column_index = {selected_column_index}\")    \n",
    "    data.drop(data.columns[selected_column_index], inplace=True, axis=1)    \n",
    "    # We generate the branches **recursively**\n",
    "    # If the answer to the question was \"yes\"\n",
    "    generate_tree(data[mask], tree, branch=\"+\", parent=node)\n",
    "    # If the answer to the question was \"false\"\n",
    "    generate_tree(data[~mask], tree, branch=\"-\", parent=node)\n",
    "    \n",
    "# The tree is generated\n",
    "generate_tree(df, tree)\n",
    "# The tree is plotted\n",
    "tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T09:39:01.227691Z",
     "start_time": "2021-02-09T09:39:01.223697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of the tree: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Depth of the tree:\", tree.depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it!\n",
    "\n",
    "Just enjoy what you have achieved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T09:39:09.359112Z",
     "start_time": "2021-02-09T09:39:05.416230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick an animal!\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[182], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPick an animal!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m---> 16\u001b[0m question \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mchildren(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Have we found the answer?\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m question\u001b[38;5;241m.\u001b[39mis_leaf():\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# No need to add code here!\n",
    "# Just run this and enjoy :)\n",
    "def ask_yesno(question):\n",
    "    \"\"\"Checks that the written answer is valid. Iterates otherwise.\"\"\"\n",
    "    while True:\n",
    "        answer = input(question + \" \").lower().strip()\n",
    "        if answer == \"y\" or answer == \"yes\":\n",
    "            return True\n",
    "        if answer == \"n\" or answer == \"no\":\n",
    "            return False\n",
    "        print(\"Just answer 'yes' or 'no'.\")\n",
    "\n",
    "print(\"Pick an animal!\")\n",
    "print()\n",
    "\n",
    "question = tree.children(\"root\")[0]\n",
    "while True:\n",
    "    # Have we found the answer?\n",
    "    if question.is_leaf():\n",
    "        print(\"I think you chose a \" + question.tag)\n",
    "        break\n",
    "    # Otherwise we keep asking\n",
    "    answer = ask_yesno(question.tag)\n",
    "    children = tree.children(question.identifier)\n",
    "    question = children[0] if answer else children[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
